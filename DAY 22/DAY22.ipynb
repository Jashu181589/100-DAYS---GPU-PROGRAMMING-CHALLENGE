{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2492478a",
   "metadata": {},
   "source": [
    "# DAY 22: Expectation-Maximization (EM) Algorithm in CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e8815",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile em_cuda.cu\n",
    "// nvcc em_cuda.cu -o em_cuda\n",
    "\n",
    "#include <iostream>\n",
    "#include <cmath>\n",
    "#include <cstdlib>\n",
    "#include <ctime>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#ifndef M_PI\n",
    "#define M_PI 3.14159265358979323846\n",
    "#endif\n",
    "\n",
    "// Define number of clusters and data points\n",
    "#define NUM_CLUSTERS 2     // number of clusters\n",
    "#define N 1024             // number of data points\n",
    "#define THREADS_PER_BLOCK 256\n",
    "\n",
    "// CUDA error checking macro\n",
    "#define CUDA_CHECK(call) \\\n",
    "    do { \\\n",
    "        cudaError_t error = call; \\\n",
    "        if (error != cudaSuccess) { \\\n",
    "            std::cerr << \"CUDA Error: \" << cudaGetErrorString(error) \\\n",
    "                      << \" at \" << __FILE__ << \":\" << __LINE__ << std::endl; \\\n",
    "            exit(EXIT_FAILURE); \\\n",
    "        } \\\n",
    "    } while (0)\n",
    "\n",
    "// E-step kernel\n",
    "__global__ void eStepKernel(float* data, int N, float* mu, float* sigma, \n",
    "                           float* pival, float* responsibilities) {\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if (idx < N) {\n",
    "        float x = data[idx];\n",
    "        float probs[NUM_CLUSTERS];\n",
    "        float sum = 0.0f;\n",
    "        \n",
    "        for (int k = 0; k < NUM_CLUSTERS; k++) {\n",
    "            float diff = x - mu[k];\n",
    "            float exponent = -0.5f * (diff * diff) / (sigma[k] * sigma[k]);\n",
    "            float gauss = (1.0f / (sqrtf(2.0f * M_PI) * sigma[k])) * expf(exponent);\n",
    "            probs[k] = pival[k] * gauss;\n",
    "            sum += probs[k];\n",
    "        }\n",
    "        \n",
    "        for (int k = 0; k < NUM_CLUSTERS; k++) {\n",
    "            responsibilities[idx * NUM_CLUSTERS + k] = probs[k] / sum;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// M-step kernel\n",
    "__global__ void mStepKernel(float* data, int N, float* responsibilities,\n",
    "                           float* sum_gamma, float* sum_x, float* sum_x2) {\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if (idx < N) {\n",
    "        float x = data[idx];\n",
    "        for (int k = 0; k < NUM_CLUSTERS; k++) {\n",
    "            float gamma = responsibilities[idx * NUM_CLUSTERS + k];\n",
    "            atomicAdd(&sum_gamma[k], gamma);\n",
    "            atomicAdd(&sum_x[k], gamma * x);\n",
    "            atomicAdd(&sum_x2[k], gamma * x * x);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    // Seed the random number generator\n",
    "    srand(static_cast<unsigned>(time(NULL)));\n",
    "\n",
    "    // Generate synthetic 1D data\n",
    "    float h_data[N];\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        if (i < N/2) {\n",
    "            h_data[i] = 2.0f + static_cast<float>(rand()) / RAND_MAX;\n",
    "        } else {\n",
    "            h_data[i] = 8.0f + static_cast<float>(rand()) / RAND_MAX;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Initial parameters (host)\n",
    "    float h_mu[NUM_CLUSTERS] = {1.0f, 9.0f};           // means\n",
    "    float h_sigma[NUM_CLUSTERS] = {1.0f, 1.0f};        // standard deviations\n",
    "    float h_pival[NUM_CLUSTERS] = {0.5f, 0.5f};        // mixing coefficients\n",
    "\n",
    "    // Allocate device memory\n",
    "    float *d_data, *d_mu, *d_sigma, *d_pival;\n",
    "    float *d_responsibilities, *d_sum_gamma, *d_sum_x, *d_sum_x2;\n",
    "\n",
    "    CUDA_CHECK(cudaMalloc(&d_data, N * sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_mu, NUM_CLUSTERS * sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_sigma, NUM_CLUSTERS * sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_pival, NUM_CLUSTERS * sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_responsibilities, N * NUM_CLUSTERS * sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_sum_gamma, NUM_CLUSTERS * sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_sum_x, NUM_CLUSTERS * sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_sum_x2, NUM_CLUSTERS * sizeof(float)));\n",
    "\n",
    "    // Copy data and initial parameters to device\n",
    "    CUDA_CHECK(cudaMemcpy(d_data, h_data, N * sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_mu, h_mu, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_sigma, h_sigma, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_pival, h_pival, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
    "\n",
    "    // Calculate grid dimensions\n",
    "    int blocks = (N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n",
    "    \n",
    "    // Host arrays for M-step\n",
    "    float h_sum_gamma[NUM_CLUSTERS];\n",
    "    float h_sum_x[NUM_CLUSTERS];\n",
    "    float h_sum_x2[NUM_CLUSTERS];\n",
    "\n",
    "    // EM iterations\n",
    "    int maxIter = 100;\n",
    "    for (int iter = 0; iter < maxIter; iter++) {\n",
    "        // E-step\n",
    "        eStepKernel<<<blocks, THREADS_PER_BLOCK>>>(d_data, N, d_mu, d_sigma, \n",
    "                                                  d_pival, d_responsibilities);\n",
    "        CUDA_CHECK(cudaDeviceSynchronize());\n",
    "\n",
    "        // Reset accumulators\n",
    "        CUDA_CHECK(cudaMemset(d_sum_gamma, 0, NUM_CLUSTERS * sizeof(float)));\n",
    "        CUDA_CHECK(cudaMemset(d_sum_x, 0, NUM_CLUSTERS * sizeof(float)));\n",
    "        CUDA_CHECK(cudaMemset(d_sum_x2, 0, NUM_CLUSTERS * sizeof(float)));\n",
    "\n",
    "        // M-step accumulation\n",
    "        mStepKernel<<<blocks, THREADS_PER_BLOCK>>>(d_data, N, d_responsibilities,\n",
    "                                                  d_sum_gamma, d_sum_x, d_sum_x2);\n",
    "        CUDA_CHECK(cudaDeviceSynchronize());\n",
    "\n",
    "        // Copy results back to host\n",
    "        CUDA_CHECK(cudaMemcpy(h_sum_gamma, d_sum_gamma, NUM_CLUSTERS * sizeof(float), cudaMemcpyDeviceToHost));\n",
    "        CUDA_CHECK(cudaMemcpy(h_sum_x, d_sum_x, NUM_CLUSTERS * sizeof(float), cudaMemcpyDeviceToHost));\n",
    "        CUDA_CHECK(cudaMemcpy(h_sum_x2, d_sum_x2, NUM_CLUSTERS * sizeof(float), cudaMemcpyDeviceToHost));\n",
    "\n",
    "        // Update parameters\n",
    "        for (int k = 0; k < NUM_CLUSTERS; k++) {\n",
    "            if (h_sum_gamma[k] > 1e-6f) {\n",
    "                // Update mean\n",
    "                h_mu[k] = h_sum_x[k] / h_sum_gamma[k];\n",
    "                \n",
    "                // Update variance and standard deviation\n",
    "                float variance = h_sum_x2[k] / h_sum_gamma[k] - h_mu[k] * h_mu[k];\n",
    "                h_sigma[k] = sqrtf(fmax(variance, 1e-6f));\n",
    "                \n",
    "                // Update mixing coefficient\n",
    "                h_pival[k] = h_sum_gamma[k] / N;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Copy updated parameters back to device\n",
    "        CUDA_CHECK(cudaMemcpy(d_mu, h_mu, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
    "        CUDA_CHECK(cudaMemcpy(d_sigma, h_sigma, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
    "        CUDA_CHECK(cudaMemcpy(d_pival, h_pival, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
    "\n",
    "        // Print current parameters\n",
    "        if (iter % 10 == 0) {  // Print every 10 iterations\n",
    "            std::cout << \"Iteration \" << iter << \":\\n\";\n",
    "            for (int k = 0; k < NUM_CLUSTERS; k++) {\n",
    "                std::cout << \"Cluster \" << k << \": \"\n",
    "                         << \"mu = \" << h_mu[k] << \", \"\n",
    "                         << \"sigma = \" << h_sigma[k] << \", \"\n",
    "                         << \"pi = \" << h_pival[k] << std::endl;\n",
    "            }\n",
    "            std::cout << std::endl;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Free device memory\n",
    "    cudaFree(d_data);\n",
    "    cudaFree(d_mu);\n",
    "    cudaFree(d_sigma);\n",
    "    cudaFree(d_pival);\n",
    "    cudaFree(d_responsibilities);\n",
    "    cudaFree(d_sum_gamma);\n",
    "    cudaFree(d_sum_x);\n",
    "    cudaFree(d_sum_x2);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7fb47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and run the CUDA EM algorithm\n",
    "!nvcc em_cuda.cu -o em_cuda\n",
    "!./em_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b184ff",
   "metadata": {},
   "source": [
    "## Output:\n",
    "```\n",
    "Iteration 0:\n",
    "Cluster 0: mu = 2.49766, sigma = 0.287805, pi = 0.5\n",
    "Cluster 1: mu = 8.49884, sigma = 0.286726, pi = 0.5\n",
    "\n",
    "Iteration 10:\n",
    "Cluster 0: mu = 2.49766, sigma = 0.287805, pi = 0.5\n",
    "Cluster 1: mu = 8.49884, sigma = 0.286726, pi = 0.5\n",
    "\n",
    "Iteration 20:\n",
    "Cluster 0: mu = 2.49766, sigma = 0.287805, pi = 0.5\n",
    "Cluster 1: mu = 8.49884, sigma = 0.286726, pi = 0.5\n",
    "\n",
    "Iteration 30:\n",
    "Cluster 0: mu = 2.49766, sigma = 0.287805, pi = 0.5\n",
    "Cluster 1: mu = 8.49884, sigma = 0.286726, pi = 0.5\n",
    "\n",
    "Iteration 40:\n",
    "Cluster 0: mu = 2.49766, sigma = 0.287805, pi = 0.5\n",
    "Cluster 1: mu = 8.49884, sigma = 0.286726, pi = 0.5\n",
    "\n",
    "Iteration 50:\n",
    "Cluster 0: mu = 2.49766, sigma = 0.287805, pi = 0.5\n",
    "Cluster 1: mu = 8.49884, sigma = 0.286726, pi = 0.5\n",
    "\n",
    "Iteration 60:\n",
    "Cluster 0: mu = 2.49766, sigma = 0.287805, pi = 0.5\n",
    "Cluster 1: mu = 8.49884, sigma = 0.286726, pi = 0.5\n",
    "\n",
    "Iteration 70:\n",
    "Cluster 0: mu = 2.49766, sigma = 0.287805, pi = 0.5\n",
    "Cluster 1: mu = 8.49884, sigma = 0.286726, pi = 0.5\n",
    "\n",
    "Iteration 80:\n",
    "Cluster 0: mu = 2.49766, sigma = 0.287805, pi = 0.5\n",
    "Cluster 1: mu = 8.49884, sigma = 0.286726, pi = 0.5\n",
    "\n",
    "Iteration 90:\n",
    "Cluster 0: mu = 2.49766, sigma = 0.287805, pi = 0.5\n",
    "Cluster 1: mu = 8.49884, sigma = 0.286726, pi = 0.5\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
