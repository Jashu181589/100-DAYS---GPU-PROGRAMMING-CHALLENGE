{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003dacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lbfgs_demo.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "\n",
    "// Kernel to compute dot product using shared memory reduction.\n",
    "__global__ void dotProductKernel(const double* a, const double* b, double* result, int n) {\n",
    "    __shared__ double cache[256];\n",
    "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    int cacheIndex = threadIdx.x;\n",
    "    double temp = 0.0;\n",
    "    while(tid < n) {\n",
    "        temp += a[tid] * b[tid];\n",
    "        tid += blockDim.x * gridDim.x;\n",
    "    }\n",
    "    cache[cacheIndex] = temp;\n",
    "    __syncthreads();\n",
    "    // Reduction in shared memory.\n",
    "    for (int stride = blockDim.x/2; stride > 0; stride /= 2) {\n",
    "        if(cacheIndex < stride)\n",
    "            cache[cacheIndex] += cache[cacheIndex + stride];\n",
    "        __syncthreads();\n",
    "    }\n",
    "    if(cacheIndex == 0)\n",
    "        atomicAdd(result, cache[0]);\n",
    "}\n",
    "\n",
    "// Kernel for vector subtraction: a = a - scalar * b.\n",
    "__global__ void vectorSubKernel(double* a, const double* b, double scalar, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if(idx < n) {\n",
    "        a[idx] -= scalar * b[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "// Kernel for vector scaling: a = scalar * a.\n",
    "__global__ void vectorScaleKernel(double* a, double scalar, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if(idx < n) {\n",
    "        a[idx] *= scalar;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Kernel for vector addition: a = a + scalar * b.\n",
    "__global__ void vectorAddKernel(double* a, const double* b, double scalar, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if(idx < n) {\n",
    "        a[idx] += scalar * b[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "// Helper function to launch a dot product kernel and retrieve result.\n",
    "double gpuDot(const double* d_a, const double* d_b, int n) {\n",
    "    double h_result = 0.0;\n",
    "    double* d_result;\n",
    "    cudaMalloc(&d_result, sizeof(double));\n",
    "    cudaMemset(d_result, 0, sizeof(double));\n",
    "\n",
    "    int blockSize = 256;\n",
    "    int gridSize = (n + blockSize - 1) / blockSize;\n",
    "    dotProductKernel<<<gridSize, blockSize>>>(d_a, d_b, d_result, n);\n",
    "    cudaMemcpy(&h_result, d_result, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "    cudaFree(d_result);\n",
    "    return h_result;\n",
    "}\n",
    "\n",
    "// Example: one iteration of simplified L-BFGS with a single correction pair.\n",
    "int main() {\n",
    "    const int n = 1024;       // dimension of the problem\n",
    "    const int blockSize = 256;\n",
    "    const int gridSize = (n + blockSize - 1) / blockSize;\n",
    "\n",
    "    // Allocate host memory.\n",
    "    double *h_x = (double*)malloc(n * sizeof(double));\n",
    "    double *h_grad = (double*)malloc(n * sizeof(double));\n",
    "    double *h_s = (double*)malloc(n * sizeof(double)); // previous step: s = x_{k+1} - x_k\n",
    "    double *h_y = (double*)malloc(n * sizeof(double)); // difference in gradients: y = grad_{k+1} - grad_k\n",
    "\n",
    "    // Initialize with dummy data.\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        h_x[i] = 1.0;       // initial parameter\n",
    "        h_grad[i] = 0.5;    // current gradient\n",
    "        h_s[i] = 0.1;       // example previous step\n",
    "        h_y[i] = 0.2;       // example gradient difference\n",
    "    }\n",
    "\n",
    "    // Allocate device memory.\n",
    "    double *d_x, *d_grad, *d_s, *d_y, *d_q, *d_r;\n",
    "    cudaMalloc(&d_x, n * sizeof(double));\n",
    "    cudaMalloc(&d_grad, n * sizeof(double));\n",
    "    cudaMalloc(&d_s, n * sizeof(double));\n",
    "    cudaMalloc(&d_y, n * sizeof(double));\n",
    "    cudaMalloc(&d_q, n * sizeof(double));\n",
    "    cudaMalloc(&d_r, n * sizeof(double));\n",
    "\n",
    "    // Copy data to device.\n",
    "    cudaMemcpy(d_x, h_x, n * sizeof(double), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_grad, h_grad, n * sizeof(double), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_s, h_s, n * sizeof(double), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_y, h_y, n * sizeof(double), cudaMemcpyHostToDevice);\n",
    "\n",
    "    // -------- Two-loop recursion (simplified for m = 1) --------\n",
    "    // 1. Set q = grad.\n",
    "    cudaMemcpy(d_q, d_grad, n * sizeof(double), cudaMemcpyDeviceToDevice);\n",
    "\n",
    "    // 2. Compute rho = 1 / dot(s, y)\n",
    "    double dot_sy = gpuDot(d_s, d_y, n);\n",
    "    double rho = 1.0 / dot_sy;\n",
    "\n",
    "    // 3. Compute alpha = rho * dot(s, q)\n",
    "    double dot_sq = gpuDot(d_s, d_q, n);\n",
    "    double alpha = rho * dot_sq;\n",
    "\n",
    "    // 4. Update q = q - alpha * y.\n",
    "    vectorSubKernel<<<gridSize, blockSize>>>(d_q, d_y, alpha, n);\n",
    "\n",
    "    // 5. Compute H0 = dot(s,y) / dot(y,y) (scalar for initial Hessian approximation).\n",
    "    double dot_yy = gpuDot(d_y, d_y, n);\n",
    "    double H0 = dot_sy / dot_yy;\n",
    "\n",
    "    // 6. Set r = H0 * q. (scale q and store in r)\n",
    "    cudaMemcpy(d_r, d_q, n * sizeof(double), cudaMemcpyDeviceToDevice);\n",
    "    vectorScaleKernel<<<gridSize, blockSize>>>(d_r, H0, n);\n",
    "\n",
    "    // 7. Compute beta = rho * dot(y, r)\n",
    "    double dot_yr = gpuDot(d_y, d_r, n);\n",
    "    double beta = rho * dot_yr;\n",
    "\n",
    "    // 8. Update r = r + s * (alpha - beta)\n",
    "    double scalar = (alpha - beta);\n",
    "    vectorAddKernel<<<gridSize, blockSize>>>(d_r, d_s, scalar, n);\n",
    "\n",
    "    // Now the search direction is given by: direction = -r.\n",
    "    vectorScaleKernel<<<gridSize, blockSize>>>(d_r, -1.0, n);\n",
    "\n",
    "    // -------- Update parameters: x_new = x + step * direction --------\n",
    "    double step = 0.1;  // example step length (in practice, found via line search)\n",
    "    vectorAddKernel<<<gridSize, blockSize>>>(d_x, d_r, step, n);\n",
    "\n",
    "    // Copy the updated x back to host.\n",
    "    cudaMemcpy(h_x, d_x, n * sizeof(double), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Print the first 10 updated parameters.\n",
    "    printf(\"Updated parameters (first 10 values):\\n\");\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        printf(\"x[%d] = %f\\n\", i, h_x[i]);\n",
    "    }\n",
    "\n",
    "    // Free device memory.\n",
    "    cudaFree(d_x);\n",
    "    cudaFree(d_grad);\n",
    "    cudaFree(d_s);\n",
    "    cudaFree(d_y);\n",
    "    cudaFree(d_q);\n",
    "    cudaFree(d_r);\n",
    "\n",
    "    // Free host memory.\n",
    "    free(h_x);\n",
    "    free(h_grad);\n",
    "    free(h_s);\n",
    "    free(h_y);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f935d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and run the CUDA L-BFGS demo (requires nvcc/CUDA)\n",
    "!nvcc -O3 lbfgs_demo.cu -o lbfgs_demo && ./lbfgs_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f927b5b4",
   "metadata": {},
   "source": [
    "## Output:\n",
    "```\n",
    "Updated parameters (first 10 values):\n",
    "x[0] = 1.010000\n",
    "x[1] = 1.010000\n",
    "...\n",
    "```\n",
    "Note: This example runs one L-BFGS update using m=1 (one correction pair). For real problems use robust line-search and multiple pairs."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
