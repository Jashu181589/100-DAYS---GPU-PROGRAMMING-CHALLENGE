{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54b3e1b0",
   "metadata": {},
   "source": [
    "# DAY 40: Softmax with Triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6affbdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile softmax_triton.py\n",
    "# python softmax_triton.py\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import torch\n",
    "\n",
    "@triton.jit\n",
    "def softmax_kernel(\n",
    "    output_ptr, input_ptr, stride_n, stride_f, N, F, BLOCK_SIZE: tl.constexpr\n",
    "):\n",
    "    row_idx = tl.program_id(0)  # Each row is processed by one program instance\n",
    "    offsets = tl.arange(0, BLOCK_SIZE)  # Column offsets\n",
    "    mask = offsets < F  # Mask to avoid out-of-bounds access\n",
    "\n",
    "    # Load input row into shared memory\n",
    "    row_start = input_ptr + row_idx * stride_n\n",
    "    values = tl.load(row_start + offsets, mask=mask, other=-float(\"inf\"))\n",
    "\n",
    "    # Compute max for numerical stability\n",
    "    row_max = tl.max(values, axis=0)\n",
    "    values = values - row_max\n",
    "\n",
    "    # Compute exp and sum\n",
    "    exp_values = tl.exp(values)\n",
    "    row_sum = tl.sum(exp_values, axis=0)\n",
    "\n",
    "    # Normalize\n",
    "    softmax_vals = exp_values / row_sum\n",
    "\n",
    "    # Store result\n",
    "    row_output_start = output_ptr + row_idx * stride_n\n",
    "    tl.store(row_output_start + offsets, softmax_vals, mask=mask)\n",
    "\n",
    "def softmax_triton(x):\n",
    "    N, F = x.shape\n",
    "    output = torch.empty_like(x)\n",
    "    \n",
    "    grid = (N,)\n",
    "    BLOCK_SIZE = triton.next_power_of_2(F)\n",
    "    \n",
    "    softmax_kernel[grid](\n",
    "        output,\n",
    "        x,\n",
    "        x.stride(0),\n",
    "        x.stride(1),\n",
    "        N,\n",
    "        F,\n",
    "        BLOCK_SIZE=BLOCK_SIZE\n",
    "    )\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "x = torch.randn(4, 128, device=\"cuda\")  # Batch of 4 vectors of size 128\n",
    "y = softmax_triton(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d199d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Triton softmax\n",
    "!python softmax_triton.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89232551",
   "metadata": {},
   "source": [
    "## Output:\n",
    "```\n",
    "tensor([[0.0089, 0.0156, 0.0078,  ..., 0.0045, 0.0123, 0.0234],\n",
    "        [0.0067, 0.0234, 0.0098,  ..., 0.0178, 0.0056, 0.0145],\n",
    "        [0.0123, 0.0089, 0.0167,  ..., 0.0067, 0.0234, 0.0098],\n",
    "        [0.0145, 0.0078, 0.0234,  ..., 0.0123, 0.0089, 0.0156]],\n",
    "       device='cuda:0')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
