{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DAY 17: Vector Addition using cuBLAS\n",
        "\n",
        "This notebook demonstrates vector addition using the cuBLAS library, which provides optimized BLAS (Basic Linear Algebra Subprograms) operations on NVIDIA GPUs.\n",
        "\n",
        "## Key Concepts:\n",
        "- cuBLAS library usage\n",
        "- SAXPY operation (Single-precision A*X Plus Y)\n",
        "- GPU memory management with cuBLAS\n",
        "- Handle-based API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl5Ju2SUTqdu",
        "outputId": "e49d5c98-7292-4c76-9a72-a53f40059151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing VectorAdditionCublas.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile VectorAdditionCublas.cu\n",
        "// nvcc vec_cublas.cu -o vec_cublas -lstdc++ -lcublas\n",
        "\n",
        "#include <iostream>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "int main() {\n",
        "    const int N = 10;\n",
        "    float A[N], B[N], C[N];\n",
        "\n",
        "    // Initialize input vectors (you might want to add your own initialization)\n",
        "    for(int i = 0; i < N; i++) {\n",
        "        A[i] = i;\n",
        "        B[i] = i;\n",
        "    }\n",
        "\n",
        "    // Create cuBLAS handle\n",
        "    cublasHandle_t handle;\n",
        "    cublasCreate(&handle);\n",
        "\n",
        "    // Allocate device memory\n",
        "    float *d_a, *d_b;\n",
        "    cudaMalloc(&d_a, N * sizeof(float));\n",
        "    cudaMalloc(&d_b, N * sizeof(float));\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(d_a, A, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, B, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Scaling factors\n",
        "    const float alpha = 1.0f;\n",
        "\n",
        "    // Perform vector addition: C = alpha*A + B\n",
        "    cublasSaxpy(handle, N, &alpha, d_a, 1, d_b, 1);\n",
        "\n",
        "    // Copy result back to host (result is in d_b)\n",
        "    cudaMemcpy(C, d_b, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print results\n",
        "    for(int i = 0; i < N; i++) {\n",
        "        std::cout << C[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    // Cleanup\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cublasDestroy(handle);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjrDn8_gV-yD"
      },
      "outputs": [],
      "source": [
        "# Compile and run the cuBLAS vector addition program\n",
        "!nvcc VectorAdditionCublas.cu -o VectorAdditionCublas -lstdc++ -lcublas\n",
        "!./VectorAdditionCublas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output Explanation:\n",
        "The program performs vector addition using cuBLAS SAXPY operation:\n",
        "- A[i] = i (values 0, 1, 2, ..., 9)\n",
        "- B[i] = i (values 0, 1, 2, ..., 9)\n",
        "- Result C = A + B (values 0, 2, 4, ..., 18)\n",
        "\n",
        "The cuBLAS SAXPY function computes: `y = alpha*x + y`, where alpha=1.0, x=A, y=B."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
