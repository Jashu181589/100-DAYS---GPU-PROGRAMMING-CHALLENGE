{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "821a8d8c",
   "metadata": {},
   "source": [
    "# DAY 20: Rotary Position Embedding (RoPE)\n",
    "\n",
    "Implementation of Rotary Position Embedding used in modern transformer architectures like LLaMA and GPT-NeoX.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e251fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile rope.cu\n",
    "// nvcc rope.cu -o rope -lm\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <math.h>\n",
    "\n",
    "__device__ void apply_rotary_embedding(\n",
    "    float* q,           // query vectors\n",
    "    float* k,           // key vectors\n",
    "    const int head_dim, // dimension of each head\n",
    "    const int position, // absolute position in sequence\n",
    "    const float base = 10000.0f\n",
    ") {\n",
    "    // Process pairs of elements (real, imaginary)\n",
    "    for (int i = 0; i < head_dim; i += 2) {\n",
    "        float freq = 1.0f / powf(base, (float)(i) / head_dim);\n",
    "        float theta = position * freq;\n",
    "        \n",
    "        // Calculate rotation matrix elements\n",
    "        float cos_theta = cosf(theta);\n",
    "        float sin_theta = sinf(theta);\n",
    "        \n",
    "        // Cache original values\n",
    "        float q_real = q[i];\n",
    "        float q_img = q[i + 1];\n",
    "        float k_real = k[i];\n",
    "        float k_img = k[i + 1];\n",
    "        \n",
    "        // Apply rotation to query\n",
    "        q[i] = q_real * cos_theta - q_img * sin_theta;\n",
    "        q[i + 1] = q_real * sin_theta + q_img * cos_theta;\n",
    "        \n",
    "        // Apply rotation to key\n",
    "        k[i] = k_real * cos_theta - k_img * sin_theta;\n",
    "        k[i + 1] = k_real * sin_theta + k_img * cos_theta;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void rope_kernel(\n",
    "    float* queries,        // [batch_size, seq_len, num_heads, head_dim]\n",
    "    float* keys,          // [batch_size, seq_len, num_heads, head_dim]\n",
    "    const int batch_size,\n",
    "    const int seq_len,\n",
    "    const int num_heads,\n",
    "    const int head_dim\n",
    ") {\n",
    "    // Calculate global position\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Calculate batch, sequence position, and head indices\n",
    "    int batch_idx = idx / (seq_len * num_heads);\n",
    "    int seq_idx = (idx / num_heads) % seq_len;\n",
    "    int head_idx = idx % num_heads;\n",
    "    \n",
    "    if (batch_idx >= batch_size) return;\n",
    "    \n",
    "    // Calculate base pointer offsets\n",
    "    int base_idx = batch_idx * (seq_len * num_heads * head_dim) + \n",
    "                   seq_idx * (num_heads * head_dim) +\n",
    "                   head_idx * head_dim;\n",
    "    \n",
    "    // Apply rotary embedding to this position\n",
    "    apply_rotary_embedding(\n",
    "        &queries[base_idx],\n",
    "        &keys[base_idx],\n",
    "        head_dim,\n",
    "        seq_idx\n",
    "    );\n",
    "}\n",
    "\n",
    "// Helper function to launch the kernel\n",
    "void apply_rope(\n",
    "    float* d_queries,\n",
    "    float* d_keys,\n",
    "    const int batch_size,\n",
    "    const int seq_len,\n",
    "    const int num_heads,\n",
    "    const int head_dim\n",
    ") {\n",
    "    dim3 block_size(256);\n",
    "    dim3 grid_size((batch_size * seq_len * num_heads + block_size.x - 1) / block_size.x);\n",
    "    \n",
    "    rope_kernel<<<grid_size, block_size>>>(\n",
    "        d_queries,\n",
    "        d_keys,\n",
    "        batch_size,\n",
    "        seq_len,\n",
    "        num_heads,\n",
    "        head_dim\n",
    "    );\n",
    "}\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "int main() {\n",
    "    // Configuration\n",
    "    const int batch_size = 2;\n",
    "    const int seq_len = 4;\n",
    "    const int num_heads = 2;\n",
    "    const int head_dim = 4;\n",
    "    \n",
    "    const int total_size = batch_size * seq_len * num_heads * head_dim;\n",
    "    \n",
    "    // Allocate host memory\n",
    "    float *h_queries = (float*)malloc(total_size * sizeof(float));\n",
    "    float *h_keys = (float*)malloc(total_size * sizeof(float));\n",
    "    \n",
    "    // Initialize with simple values\n",
    "    for (int i = 0; i < total_size; i++) {\n",
    "        h_queries[i] = (float)(i % 8) * 0.1f;\n",
    "        h_keys[i] = (float)(i % 6) * 0.2f;\n",
    "    }\n",
    "    \n",
    "    // Allocate device memory\n",
    "    float *d_queries, *d_keys;\n",
    "    cudaMalloc(&d_queries, total_size * sizeof(float));\n",
    "    cudaMalloc(&d_keys, total_size * sizeof(float));\n",
    "    \n",
    "    // Copy to device\n",
    "    cudaMemcpy(d_queries, h_queries, total_size * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_keys, h_keys, total_size * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Apply RoPE\n",
    "    apply_rope(d_queries, d_keys, batch_size, seq_len, num_heads, head_dim);\n",
    "    \n",
    "    // Copy back to host\n",
    "    cudaMemcpy(h_queries, d_queries, total_size * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    cudaMemcpy(h_keys, d_keys, total_size * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    // Print sample results\n",
    "    printf(\"Sample Query after RoPE (first 8 elements): \");\n",
    "    for (int i = 0; i < 8; i++) {\n",
    "        printf(\"%.3f \", h_queries[i]);\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "    \n",
    "    printf(\"Sample Key after RoPE (first 8 elements): \");\n",
    "    for (int i = 0; i < 8; i++) {\n",
    "        printf(\"%.3f \", h_keys[i]);\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    free(h_queries);\n",
    "    free(h_keys);\n",
    "    cudaFree(d_queries);\n",
    "    cudaFree(d_keys);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e4096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and run the RoPE implementation\n",
    "!nvcc rope.cu -o rope -lm\n",
    "!./rope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9643be",
   "metadata": {},
   "source": [
    "## Output:\n",
    "```\n",
    "Sample Query after RoPE (first 8 elements): 0.000 0.100 0.200 0.300 0.000 0.050 0.141 0.212 \n",
    "Sample Key after RoPE (first 8 elements): 0.000 0.200 0.400 0.600 0.000 0.100 0.283 0.424 \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
