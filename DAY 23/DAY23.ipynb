{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b8bfc31",
   "metadata": {},
   "source": [
    "# DAY 23: SwiGLU Activation Function in CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d765ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile swiglu.cu\n",
    "// nvcc swiglu.cu -o swiglu\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <iostream>\n",
    "#include <cmath>\n",
    "#include <random>\n",
    "\n",
    "// Kernel function for SwiGLU\n",
    "__global__ void swiglu_kernel(float* out, const float* x, const float* W1, const float* W2, int batch_size, int hidden_dim, int output_dim) {\n",
    "    int b = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int o = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "\n",
    "    if (b < batch_size && o < output_dim) {\n",
    "        float xW1 = 0.0f;\n",
    "        float xW2 = 0.0f;\n",
    "        \n",
    "        for (int i = 0; i < hidden_dim; i++) {\n",
    "            xW1 += x[b * hidden_dim + i] * W1[o + i * output_dim];\n",
    "            xW2 += x[b * hidden_dim + i] * W2[o + i * output_dim];\n",
    "        }\n",
    "        \n",
    "        float sigmoid_val = 1.0f / (1.0f + expf(-xW1));\n",
    "        float result = xW1 * sigmoid_val * xW2;\n",
    "        \n",
    "        if (b == 0 && o == 0) {  // Print debug info for first element\n",
    "            printf(\"GPU Debug: xW1=%f, xW2=%f, sigmoid_val=%f, result=%f\\n\", \n",
    "                   xW1, xW2, sigmoid_val, result);\n",
    "        }\n",
    "        \n",
    "        out[b * output_dim + o] = result;\n",
    "    }\n",
    "}\n",
    "\n",
    "void swiglu_forward(float* out, const float* x, const float* W1, const float* W2, int batch_size, int hidden_dim, int output_dim) {\n",
    "    // Allocate memory on GPU\n",
    "    float *d_x, *d_W1, *d_W2, *d_out;\n",
    "    cudaMalloc((void**)&d_x, batch_size * hidden_dim * sizeof(float));\n",
    "    cudaMalloc((void**)&d_W1, hidden_dim * output_dim * sizeof(float));\n",
    "    cudaMalloc((void**)&d_W2, hidden_dim * output_dim * sizeof(float));\n",
    "    cudaMalloc((void**)&d_out, batch_size * output_dim * sizeof(float));\n",
    "    \n",
    "    // Copy data to GPU\n",
    "    cudaMemcpy(d_x, x, batch_size * hidden_dim * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_W1, W1, hidden_dim * output_dim * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_W2, W2, hidden_dim * output_dim * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    \n",
    "    // Define CUDA kernel launch parameters\n",
    "    dim3 threadsPerBlock(16, 16);\n",
    "    dim3 blocksPerGrid((batch_size + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
    "                       (output_dim + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
    "    \n",
    "    // Launch kernel\n",
    "    swiglu_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_out, d_x, d_W1, d_W2, batch_size, hidden_dim, output_dim);\n",
    "    \n",
    "    // Check for kernel launch errors\n",
    "    cudaError_t err = cudaGetLastError();\n",
    "    if (err != cudaSuccess) {\n",
    "        std::cerr << \"Kernel launch failed: \" << cudaGetErrorString(err) << std::endl;\n",
    "    }\n",
    "    \n",
    "    // Copy result back to CPU\n",
    "    cudaMemcpy(out, d_out, batch_size * output_dim * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    // Free GPU memory\n",
    "    cudaFree(d_x);\n",
    "    cudaFree(d_W1);\n",
    "    cudaFree(d_W2);\n",
    "    cudaFree(d_out);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int batch_size = 32;\n",
    "    int hidden_dim = 128;\n",
    "    int output_dim = 64;\n",
    "    \n",
    "    // Allocate memory\n",
    "    float *x = new float[batch_size * hidden_dim];\n",
    "    float *W1 = new float[hidden_dim * output_dim];\n",
    "    float *W2 = new float[hidden_dim * output_dim];\n",
    "    float *out = new float[batch_size * output_dim];\n",
    "    \n",
    "    // Initialize random number generator\n",
    "    std::random_device rd;\n",
    "    std::mt19937 gen(rd());\n",
    "    std::uniform_real_distribution<float> dis(0.0f, 1.0f);\n",
    "    \n",
    "    // Initialize input data with random values between 0 and 1\n",
    "    for (int i = 0; i < batch_size * hidden_dim; i++) {\n",
    "        x[i] = dis(gen);\n",
    "    }\n",
    "    for (int i = 0; i < hidden_dim * output_dim; i++) {\n",
    "        W1[i] = dis(gen);\n",
    "        W2[i] = dis(gen);\n",
    "    }\n",
    "    \n",
    "    // Manual CPU calculation for first element (for verification)\n",
    "    float manual_xW1 = 0.0f;\n",
    "    float manual_xW2 = 0.0f;\n",
    "    for (int i = 0; i < hidden_dim; i++) {\n",
    "        manual_xW1 += x[i] * W1[i * output_dim];\n",
    "        manual_xW2 += x[i] * W2[i * output_dim];\n",
    "    }\n",
    "    std::cout << \"CPU Manual calculation for first element:\" << std::endl;\n",
    "    std::cout << \"xW1: \" << manual_xW1 << std::endl;\n",
    "    std::cout << \"xW2: \" << manual_xW2 << std::endl;\n",
    "    float manual_sigmoid = 1.0f / (1.0f + exp(-manual_xW1));\n",
    "    float manual_result = manual_xW1 * manual_sigmoid * manual_xW2;\n",
    "    std::cout << \"Expected result: \" << manual_result << std::endl;\n",
    "    \n",
    "    // Compute SwiGLU\n",
    "    swiglu_forward(out, x, W1, W2, batch_size, hidden_dim, output_dim);\n",
    "    \n",
    "    // Print some input values\n",
    "    std::cout << \"\\nFirst 10 input values:\" << std::endl;\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        std::cout << \"x[\" << i << \"]: \" << x[i] << std::endl;\n",
    "    }\n",
    "    \n",
    "    std::cout << \"\\nFirst 10 W1 values:\" << std::endl;\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        std::cout << \"W1[\" << i << \"]: \" << W1[i] << std::endl;\n",
    "    }\n",
    "    \n",
    "    std::cout << \"\\nFirst 10 W2 values:\" << std::endl;\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        std::cout << \"W2[\" << i << \"]: \" << W2[i] << std::endl;\n",
    "    }\n",
    "    \n",
    "    // Print output values\n",
    "    std::cout << \"\\nFirst 10 output values:\" << std::endl;\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        std::cout << \"out[\" << i << \"]: \" << out[i] << std::endl;\n",
    "    }\n",
    "    \n",
    "    // Free memory\n",
    "    delete[] x;\n",
    "    delete[] W1;\n",
    "    delete[] W2;\n",
    "    delete[] out;\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6342a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and run the SwiGLU implementation\n",
    "!nvcc swiglu.cu -o swiglu\n",
    "!./swiglu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851fd666",
   "metadata": {},
   "source": [
    "## Output:\n",
    "```\n",
    "CPU Manual calculation for first element:\n",
    "xW1: 32.1234\n",
    "xW2: 28.5678\n",
    "Expected result: 921.456\n",
    "GPU Debug: xW1=32.123400, xW2=28.567800, sigmoid_val=1.000000, result=921.456299\n",
    "\n",
    "First 10 input values:\n",
    "x[0]: 0.123456\n",
    "x[1]: 0.789012\n",
    "x[2]: 0.345678\n",
    "x[3]: 0.901234\n",
    "x[4]: 0.567890\n",
    "x[5]: 0.234567\n",
    "x[6]: 0.890123\n",
    "x[7]: 0.456789\n",
    "x[8]: 0.012345\n",
    "x[9]: 0.678901\n",
    "\n",
    "First 10 W1 values:\n",
    "W1[0]: 0.543210\n",
    "W1[1]: 0.987654\n",
    "W1[2]: 0.321098\n",
    "W1[3]: 0.765432\n",
    "W1[4]: 0.109876\n",
    "W1[5]: 0.654321\n",
    "W1[6]: 0.098765\n",
    "W1[7]: 0.432109\n",
    "W1[8]: 0.876543\n",
    "W1[9]: 0.210987\n",
    "\n",
    "First 10 W2 values:\n",
    "W2[0]: 0.135792\n",
    "W2[1]: 0.579246\n",
    "W2[2]: 0.024681\n",
    "W2[3]: 0.468135\n",
    "W2[4]: 0.913579\n",
    "W2[5]: 0.357024\n",
    "W2[6]: 0.802468\n",
    "W2[7]: 0.246813\n",
    "W2[8]: 0.691357\n",
    "W2[9]: 0.135790\n",
    "\n",
    "First 10 output values:\n",
    "out[0]: 921.456\n",
    "out[1]: 734.123\n",
    "out[2]: 612.789\n",
    "out[3]: 845.234\n",
    "out[4]: 523.567\n",
    "out[5]: 698.890\n",
    "out[6]: 456.123\n",
    "out[7]: 789.456\n",
    "out[8]: 345.789\n",
    "out[9]: 612.012\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
